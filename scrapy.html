<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>
  <meta charset="utf-8">
  <title>Thu thập dữ liệu với Scrapy, Splash, Lua - Nội dung được tạo bởi Javascript &mdash; Save and Share</title>
  <meta name="author" content="Nguyen Dac Toan KMA">

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <link href="/favicon.png" rel="icon">

  <link href="/theme/css/main.css" media="screen, projection" rel="stylesheet" type="text/css">

  <link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet"
    type="text/css">
  <link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet"
    type="text/css">

  <!-- tracking -->
  <script type="application/javascript" src="https://theodoi-phien.herokuapp.com/record.js"></script>
  <script type="application/javascript">
    window.recorder.setSession()
  </script>
</head>

<body>
  <header role="banner">
    <hgroup>
      <h1><a href="/">Save and Share</a></h1>
    </hgroup>
  </header>
  <nav role="navigation">
    <ul class="subscription" data-subscription="rss">
    </ul>


    <ul class="main-navigation">
      <li class="active">
        <a href="/category/crawl.html">Crawl</a>
      </li>
      <li>
        <a href="/category/devops.html">Devops</a>
      </li>
      <li>
        <a href="/category/programing.html">Programing</a>
      </li>
      <li>
        <a href="/category/web.html">Web</a>
      </li>
    </ul>
  </nav>
  <div id="main">
    <div id="content">
      <div>
        <article class="hentry" role="article">
          <header>
            <h1 class="entry-title">Thu thập dữ liệu với Scrapy, Splash, Lua - Nội dung được tạo bởi Javascript</h1>
            <p class="meta">
              <time datetime="2019-01-30T00:00:00+07:00" pubdate>T4 30 Tháng 1 2019</time>
            </p>
          </header>

          <div class="entry-content">
            <ul>
              <li>Thật khó để tìm thấy một trang web hiện đại không sử dụng công nghệ javascript. Khi bạn muốn lấy nội
                dung được tạo bằng javascript từ một trang web, bạn sẽ nhận ra rằng Scrapy đơn thuần không thể chạy mã
                javascript trong khi thu thập dữ liệu. Trong bài viết này, mình sẽ hướng dẫn các bạn cách thu thập dữ
                liệu từ trang <a href="https://websosanh.vn/">websosanh</a>, websosanh là công cụ tìm kiếm, so sánh giúp
                người tiêu dùng mua được sản phẩm tốt với giá rẻ nhất tại nơi bán gần nhất.</li>
            </ul>
            <h1>Quét nội dung được tạo bởi javascript</h1>
            <h2>Kiểm tra nội dung nào trên trang web sử dụng javascript</h2>
            <ul>
              <li>Khi bạn ghé thăm một trang web để thu thập dữ liệu. Bạn sẽ làm gì? Trước tiên, bạn nên kiểm tra trang
                web đó trong trình duyệt của bạn với <a
                  href="https://chrome.google.com/webstore/detail/quick-javascript-switcher/geddoclleiomckbhadiaipdggiiccfje">Quick
                  Javascript Switcher</a> là một tiện ích mở rộng của Chrome cho phép bạn kích hoạt hoặc vô hiệu hóa
                javaScript của trang web một cách nhanh chóng, nhờ đó bạn có thể dễ dàng kiểm tra xem các nội dung nào
                của trang web sử dụng javascript. Nếu bạn muốn vượt qua javaScript để tiếp cận dữ liệu bạn muốn, bạn có
                thể tham khảo 3 giải pháp dưới đây</li>
            </ul>
            <h2>Requests-HTML</h2>
            <ul>
              <li>Nếu bạn đã từng sử dụng <a href="http://docs.python-requests.org/en/master/">Requests</a> mô-đun cho
                python trước đây, gần đây nhà phát triển đã tạo ra một mô-đun mới có tên gọi <a
                  href="https://html.python-requests.org/">Requests-HTML</a> mà giờ đây cũng có khả năng hiển thị
                javaScript, giải pháp này chỉ dành cho phiên bản 3.6 của Python (tại thời điểm này). Bạn cũng có thể
                truy cập <a href="http://docs.python-requests.org/en/master/">Requests</a> để tìm hiểu thêm về mô-đun
                này hoặc nếu bạn chỉ quan tâm đến việc hiển thị javaScript thì bạn có thể truy cập <a
                  href="https://html.python-requests.org/">Requests-HTML</a> để trực tiếp tìm hiểu cách sử dụng mô-đun
                để hiển thị javaScript bằng Python.</li>
            </ul>
            <h2>Selenium</h2>
            <ul>
              <li><a href="https://selenium-python.readthedocs.io/">Selenium</a> là trình duyệt web không có giao diện
                đồ họa người dùng. Vì vậy, bạn có thể điều khiển trình duyệt thông qua giao diện API hoặc dòng lệnh. Các
                trình duyệt phổ biến như mozilla và chrome có trình điều khiển web chính thức của riêng họ . Các trình
                duyệt này có thể tải javaScript để bạn có thể sử dụng chúng trong trình cạo web của mình.</li>
            </ul>
            <h2>Splash</h2>
            <ul>
              <li><a href="https://splash.readthedocs.io/en/stable/api.html">Splash</a> cung cấp một công cụ để hiển thị
                mã javaScript cho khung trình thu thập thông tin Scrapy. Nó có các chức năng sau:</li>
            </ul>
            <div class="highlight">
              <pre><span></span>    Return a good HTML page for the user

    Concurrent rendering multiple pages

    Turn off the picture load, speed up the rendering

    Executing user – defined JS code

    Implementing user defined Lua footsteps is similar to non interface browser phantomjs. 
</pre>
            </div>


            <h2>Đánh giá các giải pháp</h2>
            <ul>
              <li>
                <p><a href="https://html.python-requests.org/">Requests-HTML</a> khá tốt và mới mẻ , tuy nhiên giải pháp
                  này chỉ dành cho phiên bản 3.6 của Python (tại thời điểm này), tài liệu tham khảo tương đối ít.</p>
              </li>
              <li>
                <p>Khi bạn chọn giữa hai lựa chọn <a href="https://selenium-python.readthedocs.io/">Selenium</a> và <a
                    href="https://splash.readthedocs.io/en/stable/api.html">Splash</a> cho dự án cạo web của mình, bạn
                  nên xem xét một yếu tố: yêu cầu tài nguyên phần cứng. <strong>Selenium</strong> tiêu thụ tài nguyên hệ
                  thống nhiều hơn khi tạo ra hàng ngàn requests trong khi chạy. Mình không khuyến khích bạn sử dụng
                  <strong>Selenium</strong> cho các dự án cạo web. Thay vào đó bạn nên thử <strong>Splash</strong>. Nó
                  được tạo để chỉ hiển thị nội dung javaScript. Đây chính xác là những gì bạn cần cho việc cạo web. </p>
              </li>
            </ul>
            <h1>Thực hành</h1>
            <h2>Mục tiêu</h2>
            <ul>
              <li>Thu thập thông tin về <strong>tên</strong>, <strong>giá thành</strong>, <strong>ảnh</strong> của sản
                phẩm bất kỳ nằm trong <strong>danh mục sản phẩm</strong>. Trong bài viết này, mình sẽ demo việc lấy dữ
                liệu từ danh mục <a href="https://websosanh.vn/dan-organ/cat-2022.htm">đàn organ</a></li>
            </ul>
            <p><img alt="Image" src="images/crawl/categori.png"></p>
            <h2>Phân tích</h2>
            <ul>
              <li>Trước tiên, mình sử dụng <a
                  href="https://chrome.google.com/webstore/detail/quick-javascript-switcher/geddoclleiomckbhadiaipdggiiccfje">Quick
                  Javascript Switcher</a> để kiểm tra xem các thành phần nào của trang web có sử dụng javascript bằng
                cách tắt <a
                  href="https://chrome.google.com/webstore/detail/quick-javascript-switcher/geddoclleiomckbhadiaipdggiiccfje">Quick
                  Javascript Switcher</a>, ngay sau hành động đó các hình ảnh về sản phẩm đồng loạt biến mất như trong
                hình ảnh bên dưới </li>
            </ul>
            <p><img alt="Image" src="images/crawl/no-js.png"></p>
            <ul>
              <li>
                <p>Như vậy <strong>ảnh sản phẩm</strong> được tạo bởi javascript.</p>
              </li>
              <li>
                <p>Một điều cần chú ý tiếp theo là trang web sử dụng phân trang. Phân trang là kỹ thuật phổ biến được
                  các nhà phát triển web sử dụng để hiển thị lượng dữ liệu lớn trong kết quả tìm kiếm hoặc danh sách
                  thay vì đặt tất cả các sản phẩm được liệt kê trên cùng một trang, vì vậy nếu bạn muốn thu thập dữ liệu
                  sản phẩm từ trang web, bạn cần cấu hình tác vụ thu thập dữ liệu của mình với phân trang để có thể lấy
                  được tất cả các sản phẩm được liệt kê trên các trang khác nhau.</p>
              </li>
              <li>
                <p>Để ý chút nữa, khi tắt <a
                    href="https://chrome.google.com/webstore/detail/quick-javascript-switcher/geddoclleiomckbhadiaipdggiiccfje">Quick
                    Javascript Switcher</a> và nhấp vào ô chuyển trang thì trang web không thực thi hành động đó, khi
                  bạn bật lại <a
                    href="https://chrome.google.com/webstore/detail/quick-javascript-switcher/geddoclleiomckbhadiaipdggiiccfje">Quick
                    Javascript Switcher</a> và lặp lại hành động chuyển trang đồng thời kiểm tra trong tab network/xhr
                  của trình duyệt chrome (Ctrl+Shift+i) thì thấy mã javaScript được thực thi và gửi một loạt yêu cầu
                  <strong>ajax</strong> đến nền trình duyệt chrome </p>
              </li>
            </ul>
            <p><img alt="Image" src="images/crawl/next-page.png"> </p>
            <ul>
              <li>Theo phân tích này mình đưa ra giải pháp sử dụng scrapy-splash cho việc bóc tách dữ liệu. Khi sử dụng
                splash, để tương tác với các phần tử javascript(mô phỏng hành vi chuyển trang của người dùng) bạn cần
                viết tập lệnh <a href="https://splash.readthedocs.io/en/stable/scripting-overview.html">lua</a>.</li>
            </ul>
            <h2>Cài đặt splash</h2>
            <ul>
              <li><a href="https://splash.readthedocs.io/en/stable/">Splash</a> chạy trên <a
                  href="https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-on-ubuntu-16-04">Docker</a>
                vậy nên đầu tiên bạn phải cài đặt <a
                  href="https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-on-ubuntu-16-04">Docker</a>
                (hiện mình đang sử dụng Ubuntu 16.04)</li>
              <li>Sau khi có Docker rồi thì bạn chạy lệnh sau:</li>
            </ul>
            <div class="highlight">
              <pre><span></span>$ sudo docker pull scrapinghub/splash
</pre>
            </div>


            <ul>
              <li>Bắt đầu với Splash(mở dịch vụ Splash trên cổng 8050 của máy tính cục bộ)</li>
            </ul>
            <div class="highlight">
              <pre><span></span>$ sudo docker run -p <span class="m">8050</span>:8050 scrapinghub/splash
</pre>
            </div>


            <p><img alt="Image" src="images/crawl/open-splash.png"></p>
            <ul>
              <li>Các bạn có thể sử dụng lệnh để thấy cổng 8050 đã mở dịch vụ</li>
            </ul>
            <p><img alt="Image" src="images/crawl/netcat.png"></p>
            <h2>Cài đặt scrapy-splash</h2>
            <ul>
              <li>Bạn nên khởi tạo môi trường ảo <a href="https://docs.python.org/3/library/venv.html">virtualenv</a>,
                cài scrapy và scrapy-splash bằng lệnh:</li>
            </ul>
            <div class="highlight">
              <pre><span></span>$ pip install scrapy scrapy-splash
</pre>
            </div>


            <h2>Khởi tạo project với scrapy</h2>
            <ul>
              <li>Khởi tạo một project với Scrapy bằng lệnh sau:</li>
            </ul>
            <div class="highlight">
              <pre><span></span>$ scrapy startproject crawl
</pre>
            </div>


            <p><img alt="Image" src="images/crawl/start.png"></p>
            <ul>
              <li>Sau đó sẽ có một project trông khá đầy đủ như thế này:</li>
            </ul>
            <p><img alt="Image" src="images/crawl/tree.png"></p>
            <ul>
              <li>Thêm config trong file settings.py như sau:</li>
            </ul>
            <div class="highlight">
              <pre><span></span>SPLASH_URL = &#39;http://127.0.0.1:8050&#39;
DUPEFILTER_CLASS = &#39;scrapy_splash.SplashAwareDupeFilter&#39;
HTTPCACHE_STORAGE = &#39;scrapy_splash.SplashAwareFSCacheStorage&#39;
COOKIES_ENABLED = True 
SPLASH_COOKIES_DEBUG = False
SPIDER_MIDDLEWARES = {
    &#39;scrapy_splash.SplashDeduplicateArgsMiddleware&#39;: 100,
}
DOWNLOADER_MIDDLEWARES = {
    &#39;scrapy_splash.SplashCookiesMiddleware&#39;: 723,
    &#39;scrapy_splash.SplashMiddleware&#39;: 725,
&#39;scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware&#39;: 810,
&#39;scrapy.downloadermiddlewares.useragent.UserAgentMiddleware&#39;: 400,
}
</pre>
            </div>


            <h2>Đặc tả dữ liệu</h2>
            <ul>
              <li>File items.py được sử dụng để khai báo những dữ liệu mà mình muốn thu thập. Trong file này có class
                CrawlItem là class được kế thừa từ class Item của Scrapy. Trong class này đã định nghĩa trước một số đối
                tượng mà Scrapy cần dùng để thu thập dữ liệu.</li>
            </ul>
            <div class="highlight">
              <pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">CrawlItem</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Item</span><span class="p">):</span>
    <span class="c1"># define the fields for your item here like:</span>
    <span class="c1"># name = scrapy.Field()</span>
    <span class="k">pass</span>
</pre>
            </div>


            <ul>
              <li>Bây giờ, mình sẽ thêm vào những dữ liệu cần thu thập gồm tên sản phẩm, giá thành và ảnh sản phẩm.</li>
            </ul>
            <div class="highlight">
              <pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">CrawlItem</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Item</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">price</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
</pre>
            </div>


            <h2>Tạo spider</h2>
            <ul>
              <li>
                <p>Tạo một file tên là <strong>websosanh.py</strong> trong thư mục spiders đã được tạo ở trên. Thư mục
                  này là nơi đưa ra các chỉ định cho Scrapy biết chính xác dữ liệu thu thập là gì. Trong thư mục này,
                  bạn có thể định nghĩa các Spider khác nhau cho các trang Web khác nhau.</p>
              </li>
              <li>
                <p>Bắt đầu bằng một class kế thừa từ class Spider của Scrapy, mình sẽ thêm vào các thuộc tính cần thiết
                  sau:</p>
              </li>
            </ul>
            <div class="highlight">
              <pre><span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="kn">import</span> <span class="nn">scrapy</span>
<span class="kn">from</span> <span class="nn">crawl.items</span> <span class="kn">import</span> <span class="n">CrawlItem</span>
<span class="kn">from</span> <span class="nn">scrapy_splash</span> <span class="kn">import</span> <span class="n">SplashRequest</span>


<span class="k">class</span> <span class="nc">WebsosanhSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;wss&quot;</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;websosanh.vn&#39;</span><span class="p">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;https://websosanh.vn/dan-organ/cat-2022.htm&quot;</span><span class="p">]</span>
</pre>
            </div>


            <ul>
              <li>Trong đó:</li>
            </ul>
            <div class="highlight">
              <pre><span></span>- name: định nghĩa tên của Spider.
- allowed_domains: chứa URL gốc của trang Web bạn muốn crawl.
- start_urls: là danh sách các URL để Spider bắt đầu quá trình thu thập dữ liệu. Tất cả mọi dữ liệu sẽ được Spider download từ các URL ở trong start_urls này.
</pre>
            </div>


            <h2>Sử dụng xpath selector</h2>
            <div class="highlight">
              <pre><span></span>XPath is a language for selecting nodes in XML documents, which can also be used with HTML.
- Scrapy’s documentation -
</pre>
            </div>


            <ul>
              <li>Mình sử dụng <strong>xpath</strong> để chọn lọc ra thành phần chính xác cần thu thập dữ liệu dưới sự
                hỗ trợ của trình duyệt Chrome với Developer Tools, ngoài ra bạn có thể sử dụng <strong>css
                  selector</strong>. Đơn giản thì chỉ cần inspect một đối tượng trên trang web sau đó copy xpath của nó
                và chỉnh sửa nếu bạn muốn.</li>
            </ul>
            <p><img alt="Image" src="images/crawl/xpath.png"></p>
            <ul>
              <li>Mình sẽ lấy XPath của phần tử chứa tên sản phẩm <code>&lt;h3 class="title"&gt;</code>, kết quả là</li>
            </ul>
            <div class="highlight">
              <pre><span></span>//*[@id=&quot;productListByType&quot;]/ul[1]/li[3]/h3/a/text()
</pre>
            </div>


            <p>Developer Tools của Chrome cũng cho phép test thử xpath trên console của Javascript, bằng cách sử dụng cú
              pháp $x(), mình sẽ test trong Javascript console:</p>
            <p><img alt="Image" src="images/crawl/test-xpath.png"></p>
            <ul>
              <li>Tiếp tục làm như vậy, bạn có thể lấy được xpath của các dữ liệu còn lại, hoặc bạn có thể tự mình chỉnh
                sửa lại xpath đã có để được kết quả tối ưu hơn.</li>
            </ul>
            <h2>Trích xuất dữ liệu</h2>
            <ul>
              <li>Bây giờ, mình sẽ chỉnh sửa <strong>websosanh.py</strong> để thêm vào XPath mong muốn.</li>
            </ul>
            <div class="highlight">
              <pre><span></span><span class="c1"># -*- coding utf-8 -*-</span>
<span class="kn">import</span> <span class="nn">scrapy</span>
<span class="kn">from</span> <span class="nn">crawl.items</span> <span class="kn">import</span> <span class="n">CrawlItem</span>
<span class="kn">from</span> <span class="nn">scrapy_splash</span> <span class="kn">import</span> <span class="n">SplashRequest</span>


<span class="k">class</span> <span class="nc">WebsosanhSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;wss&quot;</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;websosanh.vn&#39;</span><span class="p">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;https://websosanh.vn/dan-organ/cat-2022.htm&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">start_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_urls</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">SplashRequest</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;render.html&quot;</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">item</span> <span class="o">=</span> <span class="n">CrawlItem</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s2">&quot;//li[@class=&#39;item &#39;]&quot;</span><span class="p">):</span>
            <span class="n">item</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s2">&quot;./h3/a/text()&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">item</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">item</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s2">&quot;./h2/a/text()&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
            <span class="n">item</span><span class="p">[</span><span class="s2">&quot;price&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s2">&quot;./div[2]/text()&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
            <span class="n">item</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s2">&quot;./div[1]/a/img[1]/@data-src&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
            <span class="k">yield</span> <span class="n">item</span>
</pre>
            </div>


            <ul>
              <li>
                <p>Với đoạn code trên, mình sẽ duyệt qua lần lượt các sản phẩm, và gán các giá trị
                  <strong>name</strong>, <strong>price</strong>, <strong>image</strong> cho các item từ dữ liệu thu thập
                  được. Như vậy mình mới chỉ lấy được thông tin sản phẩm ở trang đầu tiên, còn các trang còn lại thì làm
                  như thế nào, có không dưới một cách để có thể duyệt qua từng trang để thu thập thông tin sản phẩm như
                  đặt giá trị tăng dần trong vòng lặp URL,...Ở đây mình sẽ sử dụng ngôn ngữ <a
                    href="https://splash.readthedocs.io/en/stable/scripting-overview.html">lua</a> để viết một đoạn
                  script nhỏ mô phỏng hành động nhấp chuột chuyển trang của người dùng. Bạn có thể nhấp vào liên kết dẫn
                  tới trang tổng quan về API Splash Lua để tìm hiểu kỹ hơn ngôn ngữ này.</p>
              </li>
              <li>
                <p>Để mô phỏng hành động nhấp chuột chuyển trang từ người dùng, đầu tiên mình sẽ tìm đến thành phần
                  chuyển trang </p>
              </li>
            </ul>
            <p><img alt="Image" src="images/crawl/next.png"></p>
            <ul>
              <li>Thật dễ dàng để tìm thấy phần tử <code>a.next</code> là phần tử chọn duy nhất cho nút tiếp theo của
                trang này. Khoan đã, nếu không để ý kĩ thì bạn sẽ rất dễ dàng bỏ qua trường hợp này, nút về cuối trang
                cũng chứa phần tử <code>a.next</code></li>
            </ul>
            <p><img alt="Image" src="images/crawl/next-2.png"></p>
            <ul>
              <li>
                <p>Dựa theo phân tích đó mình xác định được đoạn mã thực hiện hành động chuyển trang là
                  <code>$('.next')[0].click();</code> (vì mình muốn chuyển trang lần lượt chứ không phải đi về cuối
                  trang luôn nên mới có <code>[0]</code> ở đó).</p>
              </li>
              <li>
                <p>Để chắc chắc hơn mình sẽ kiểm tra hành động này trong Javascript console </p>
              </li>
            </ul>
            <p><img alt="Image" src="images/crawl/next-3.png"></p>
            <ul>
              <li>Vậy là đoạn mã trên đã đúng, giờ thì tiến hành hoàn thiện code thôi nào, mình muốn đoạn mã trên được
                lặp lại cho tới khi đi hết trang thì dừng lại, mở <strong>websosanh.py</strong> và chỉnh sửa nào</li>
            </ul>
            <div class="highlight">
              <pre><span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="kn">import</span> <span class="nn">scrapy</span>
<span class="kn">from</span> <span class="nn">crawl.items</span> <span class="kn">import</span> <span class="n">CrawlItem</span>
<span class="kn">from</span> <span class="nn">scrapy_splash</span> <span class="kn">import</span> <span class="n">SplashRequest</span>


<span class="k">class</span> <span class="nc">WebsosanhSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;wss&quot;</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;websosanh.vn&#39;</span><span class="p">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;https://websosanh.vn/dan-organ/cat-2022.htm&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">start_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_urls</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">SplashRequest</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;render.html&quot;</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>


    <span class="n">script</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        function main(splash)</span>
<span class="s2">            local url = splash.args.url</span>
<span class="s2">            assert(splash:go(url))</span>
<span class="s2">            assert(splash:wait(0.5))</span>
<span class="s2">            assert(splash:runjs(&quot;$(&#39;.next&#39;)[0].click();&quot;))</span>
<span class="s2">            return {</span>
<span class="s2">                html = splash:html(),</span>
<span class="s2">                url = splash:url(),</span>
<span class="s2">            }</span>
<span class="s2">        end</span>
<span class="s2">        &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">start_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_urls</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">SplashRequest</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;render.html&quot;</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">item</span> <span class="o">=</span> <span class="n">CrawlItem</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s2">&quot;//li[@class=&#39;item &#39;]&quot;</span><span class="p">):</span>
            <span class="n">item</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s2">&quot;./h3/a/text()&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">item</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">item</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s2">&quot;./h2/a/text()&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
            <span class="n">item</span><span class="p">[</span><span class="s2">&quot;price&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s2">&quot;./div[2]/text()&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
            <span class="n">item</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s2">&quot;./div[1]/a/img[1]/@data-src&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
            <span class="k">yield</span> <span class="n">item</span>

        <span class="k">yield</span> <span class="n">SplashRequest</span><span class="p">(</span>
            <span class="n">url</span><span class="o">=</span><span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="p">,</span>
            <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">,</span>
            <span class="n">meta</span><span class="o">=</span><span class="p">{</span>
                <span class="s2">&quot;splash&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;endpoint&quot;</span><span class="p">:</span> <span class="s2">&quot;execute&quot;</span><span class="p">,</span> <span class="s2">&quot;args&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;lua_source&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">script</span><span class="p">}}</span>
            <span class="p">},</span>
        <span class="p">)</span>
</pre>
            </div>


            <ul>
              <li>Sau khi xây dựng được công cụ thu thập dữ liệu trên, mình sẽ test khả năng cạo dữ liệu của nó, việc
                test rất đơn giản, bạn chỉ cần chạy đoạn mã sau ở trong thư mục crawl</li>
            </ul>
            <div class="highlight">
              <pre><span></span>$ scrapy crawl wss
</pre>
            </div>


            <ul>
              <li>Hình ảnh bên dưới cho thấy trình thu thập dữ liệu đang chạy cùng với dịch vụ Splash trên cổng 8050 của
                máy tính mình</li>
            </ul>
            <p><img alt="Image" src="images/crawl/run.png"></p>
            <ul>
              <li>Dữ liệu thu được hoàn toàn trùng khớp với dữ liệu của <strong>websosanh</strong> ở thời điểm mình chạy
                crawl bao gồm tên sản phẩm, giá thành, link ảnh sản phẩm</li>
            </ul>
            <div class="highlight">
              <pre><span></span>2019-01-30 00:01:58 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://websosanh.vn/dan-organ/cat-2022?pi=54.htm&gt;
{&#39;image&#39;: &#39;https://img.websosanh.vn/v2/users/wss/images/dan-organ-yamaha-psr-e353-hang/o64en7oje9yk5.jpg?compress=85&amp;width=200&#39;,
 &#39;name&#39;: &#39;Đàn Organ Yamaha PSR-E353 HÃNG YAMAHA&#39;,
 &#39;price&#39;: &#39;\n                    4.950.000 đ\n                &#39;}
</pre>
            </div>


            <ul>
              <li>Nhận thấy trình thu thập đã đi tới trang thứ <strong>54</strong> là trang cuối của danh mục
                <strong>đàn organ</strong> với sản phẩm cuối cùng có tên <strong>Đàn Organ Yamaha PSR-E353 HÃNG
                  YAMAHA</strong> trùng khớp với thông tin trên <strong>websosanh</strong> </li>
            </ul>
            <p><img alt="Image" src="images/crawl/end.png"></p>
            <ul>
              <li>Số lượng sản phẩm thu thập được là <strong>2139</strong> sản phẩm</li>
            </ul>
            <p><img alt="Image" src="images/crawl/count.png"></p>
            <h2>Kết luận</h2>
            <ul>
              <li>
                <p>Như vậy mình đã giới thiệu cho các bạn cách để thu thập dữ liệu web được tạo bởi Javascript, hi vọng
                  với bài viết này sẽ giúp ích cho các bạn trong việc crawl dữ liệu và không cảm thấy ngại khi đụng phải
                  những trang web có sử dụng tới Javascript.</p>
              </li>
              <li>
                <p>Bạn có thể tham khảo <a href="https://github.com/dactoankmapydev/Crawler_Web_Js">source của mình trên
                    github</a> nếu thấy cần thiết.</p>
              </li>
            </ul>
          </div>
          <footer>
            <p class="meta">
              <span class="byline author vcard">
                Posted by <span class="fn">
                  Nguyen Dac Toan KMA
                </span>
              </span>
              <time datetime="2019-01-30T00:00:00+07:00" pubdate>T4 30 Tháng 1 2019</time> <span class="categories">
                <a class='category' href='/category/crawl.html'>Crawl</a>
              </span>
              <span class="categories">
                <a class="category" href="/tag/crawl.html">crawl</a> </span>
            </p>
            <div class="sharing">
            </div>
          </footer>
        </article>

      </div>
      <aside class="sidebar">
        <section>
          <h1>Recent Posts</h1>
          <ul id="recent_posts">
            <li class="post">
              <a href="/go.html">Go cơ bản</a>
            </li>
            <li class="post">
              <a href="/convert.html">Xây dựng và triển khai web API chuyển đổi định dạng văn bản sang PDF</a>
            </li>
            <li class="post">
              <a href="/heroku.html">Triển khai ứng dụng Python Flask trên Heroku</a>
            </li>
            <li class="post">
              <a href="/UnitTest.html">Unit Test cơ bản</a>
            </li>
            <li class="post">
              <a href="/golang.html">Golang cơ bản (Giới thiệu và cài đặt)</a>
            </li>
          </ul>
        </section>
        <section>

          <h1>Categories</h1>
          <ul id="recent_posts">
            <li><a href="/category/crawl.html">Crawl</a></li>
            <li><a href="/category/devops.html">DevOps</a></li>
            <li><a href="/category/programing.html">Programing</a></li>
            <li><a href="/category/web.html">Web</a></li>
          </ul>
        </section>


        <section>
          <h1>Tags</h1>
          <a href="/tag/go.html">go</a>, <a href="/tag/convert-to-pdf.html">convert to pdf</a>, <a
            href="/tag/deploy.html">deploy</a>, <a href="/tag/heroku.html">heroku</a>, <a
            href="/tag/unittest.html">unittest</a>, <a href="/tag/crawl.html">crawl</a>, <a
            href="/tag/sosanhviec.html">sosanhviec</a>, <a href="/tag/pytudi.html">pytudi</a>
        </section>


        <section>
          <h1>Social</h1>
          <ul>
            <li><a href="https://github.com/dactoankmapydev" target="_blank">Github</a></li>
            <li><a href="https://www.facebook.com/toan.nguyen.31392410" target="_blank">Facebook</a></li>
            <li><a href="https://www.linkedin.com/in/dac-toan-nguyen-a94b2a146/" target="_blank">Linkedin</a></li>
          </ul>
        </section>

      </aside>
    </div>
  </div>
  <footer role="contentinfo">
    <p>
      Copyright &copy; 2019 Nguyen Dac Toan KMA &mdash;
      <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
    </p>
  </footer>
  <script src="/theme/js/modernizr-2.0.js"></script>
  <script src="/theme/js/ender.js"></script>
  <script src="/theme/js/octopress.js" type="text/javascript"></script>
</body>

</html>